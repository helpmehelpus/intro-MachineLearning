{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from PIL import Image\n",
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "from tqdm import tqdm\n",
    "import tensorflow as tf\n",
    "import keras\n",
    "import os\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense,Conv2D,Flatten,Dropout,MaxPooling2D,Activation, BatchNormalization, GlobalAveragePooling2D\n",
    "from sklearn.model_selection import train_test_split\n",
    "from keras.optimizers import *\n",
    "from keras.callbacks import CSVLogger, ModelCheckpoint, ReduceLROnPlateau\n",
    "from keras.regularizers import l2\n",
    "import matplotlib.pyplot as plt\n",
    "import cv2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>Data exploration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>has_cactus</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0004be2cfeaba1c0361d39e2b000257b.jpg</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>000c8a36845c0208e833c79c1bffedd1.jpg</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>000d1e9a533f62e55c289303b072733d.jpg</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0011485b40695e9138e92d0b3fb55128.jpg</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0014d7a11e90b62848904c1418fc8cf2.jpg</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                     id  has_cactus\n",
       "0  0004be2cfeaba1c0361d39e2b000257b.jpg           1\n",
       "1  000c8a36845c0208e833c79c1bffedd1.jpg           1\n",
       "2  000d1e9a533f62e55c289303b072733d.jpg           1\n",
       "3  0011485b40695e9138e92d0b3fb55128.jpg           1\n",
       "4  0014d7a11e90b62848904c1418fc8cf2.jpg           1"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# reading first five rows of the dataset\n",
    "training_data = pd.read_csv('./data/train.csv')\n",
    "training_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "17500"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# counting total number of entries\n",
    "training_data.has_cactus.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x7f8f74605a58>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# plot training set according to has_cactus value\n",
    "training_data['has_cactus'].value_counts().plot(kind='bar')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1    13136\n",
       "0     4364\n",
       "Name: has_cactus, dtype: int64"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# get exact count of has_cactus in training set\n",
    "training_data['has_cactus'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>Image Loading Routine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train shape:  (17500, 32, 32, 3)\n",
      "Y_train shape:  (17500,)\n"
     ]
    }
   ],
   "source": [
    "def load_images(path):\n",
    "    images = {}\n",
    "    for file in os.listdir(path):\n",
    "        filename = os.path.join(path, file)\n",
    "        images[file] = cv2.imread(filename)\n",
    "    return images\n",
    "\n",
    "training_images = load_images('./data/train')\n",
    "testing_images = load_images('./data/test')\n",
    "\n",
    "def create_train_set():\n",
    "    X_train = []\n",
    "    Y_train = []\n",
    "\n",
    "    for _, row in training_data.iterrows():\n",
    "        X_train.append(training_images[row['id']])\n",
    "        Y_train.append(int(row['has_cactus']))\n",
    "\n",
    "    X_train = np.array(X_train)\n",
    "    Y_train = np.array(Y_train)\n",
    "    return X_train, Y_train\n",
    "\n",
    "def create_test_set():\n",
    "    X_test = np.array([testing_images[f] for f in testing_images])\n",
    "    return X_test\n",
    "\n",
    "X_train, Y_train = create_train_set()\n",
    "X_test = create_test_set()\n",
    "\n",
    "print('X_train shape: ', X_train.shape)\n",
    "print('Y_train shape: ', Y_train.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3> Model creation functions\n",
    "   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# function that takes as input a model and adds a convolutional layer to it\n",
    "def add_layer(model, **args):\n",
    "    model.add(Conv2D(64, kernel_size=(3, 3), padding='same', **args))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Activation('relu'))\n",
    "    model.add(MaxPooling2D())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# function that takes as input a number of levels of convolutional layers, and creates a model\n",
    "def build_model(num_layers = 1):\n",
    "    model = Sequential()\n",
    "    \n",
    "    for i in range(num_layers):\n",
    "        if i:\n",
    "            add_layer(model)\n",
    "        else:\n",
    "            add_layer(model, input_shape=(32,32,3))\n",
    "    \n",
    "    model.add(Flatten())\n",
    "    \n",
    "    model.add(Dropout(0.4))\n",
    "    model.add(Dense(64, activation='relu'))\n",
    "    model.add(Dense(1, activation='sigmoid'))\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3> Benchmark model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/adriano/anaconda3/envs/capstone/lib/python3.6/site-packages/tensorflow/python/framework/op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n",
      "WARNING:tensorflow:From /home/adriano/anaconda3/envs/capstone/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py:3445: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_1 (Conv2D)            (None, 32, 32, 64)        1792      \n",
      "_________________________________________________________________\n",
      "batch_normalization_1 (Batch (None, 32, 32, 64)        256       \n",
      "_________________________________________________________________\n",
      "activation_1 (Activation)    (None, 32, 32, 64)        0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2 (None, 16, 16, 64)        0         \n",
      "_________________________________________________________________\n",
      "flatten_1 (Flatten)          (None, 16384)             0         \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 16384)             0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 64)                1048640   \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 1)                 65        \n",
      "=================================================================\n",
      "Total params: 1,050,753\n",
      "Trainable params: 1,050,625\n",
      "Non-trainable params: 128\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# create model and check its summary\n",
    "benchmark_model = build_model()\n",
    "benchmark_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# compile the model (using crossentropy as loss function)\n",
    "benchmark_model.compile(optimizer=RMSprop(lr=1e-4),\n",
    "              loss='binary_crossentropy',\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "random_indexes = np.random.permutation(17500)\n",
    "\n",
    "x_train = X_train[random_indexes[:7500]]\n",
    "y_train = Y_train[random_indexes[:7500]]\n",
    "\n",
    "x_valid = X_train[random_indexes[7500:]]\n",
    "y_valid = Y_train[random_indexes[7500:]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/adriano/anaconda3/envs/capstone/lib/python3.6/site-packages/tensorflow/python/ops/math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.cast instead.\n",
      "Train on 7500 samples, validate on 10000 samples\n",
      "Epoch 1/1\n",
      "7500/7500 [==============================] - 16s 2ms/step - loss: 0.2098 - acc: 0.9307 - val_loss: 0.2515 - val_acc: 0.9155\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f8f586f7cc0>"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "benchmark_model.fit(x_train, y_train, epochs = 1, batch_size = 8, validation_data = (x_valid, y_valid))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "benchmark_model.save('benchmark_model.h5')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>Intermediate model 1: 1 extra layer, epochs = 4, batch_size = 16</h3><br>\n",
    "From this step ownards, the validation data will contain 11500 entries\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "random_indexes = np.random.permutation(17500)\n",
    "\n",
    "x_train = X_train[random_indexes[:11500]]\n",
    "y_train = Y_train[random_indexes[:11500]]\n",
    "\n",
    "x_valid = X_train[random_indexes[11500:]]\n",
    "y_valid = Y_train[random_indexes[11500:]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_2 (Conv2D)            (None, 32, 32, 64)        1792      \n",
      "_________________________________________________________________\n",
      "batch_normalization_2 (Batch (None, 32, 32, 64)        256       \n",
      "_________________________________________________________________\n",
      "activation_2 (Activation)    (None, 32, 32, 64)        0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_2 (MaxPooling2 (None, 16, 16, 64)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_3 (Conv2D)            (None, 16, 16, 64)        36928     \n",
      "_________________________________________________________________\n",
      "batch_normalization_3 (Batch (None, 16, 16, 64)        256       \n",
      "_________________________________________________________________\n",
      "activation_3 (Activation)    (None, 16, 16, 64)        0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_3 (MaxPooling2 (None, 8, 8, 64)          0         \n",
      "_________________________________________________________________\n",
      "flatten_2 (Flatten)          (None, 4096)              0         \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 4096)              0         \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 64)                262208    \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              (None, 1)                 65        \n",
      "=================================================================\n",
      "Total params: 301,505\n",
      "Trainable params: 301,249\n",
      "Non-trainable params: 256\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "intermediate_model_1 = build_model(num_layers = 2)\n",
    "intermediate_model_1.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "intermediate_model_1.compile(optimizer=RMSprop(lr=1e-4),\n",
    "              loss='binary_crossentropy',\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 11500 samples, validate on 6000 samples\n",
      "Epoch 1/4\n",
      "11500/11500 [==============================] - 22s 2ms/step - loss: 0.1662 - acc: 0.9397 - val_loss: 0.0893 - val_acc: 0.9665\n",
      "Epoch 2/4\n",
      "11500/11500 [==============================] - 22s 2ms/step - loss: 0.1013 - acc: 0.9640 - val_loss: 0.0607 - val_acc: 0.9770\n",
      "Epoch 3/4\n",
      "11500/11500 [==============================] - 22s 2ms/step - loss: 0.0770 - acc: 0.9727 - val_loss: 0.1694 - val_acc: 0.9487\n",
      "Epoch 4/4\n",
      "11500/11500 [==============================] - 22s 2ms/step - loss: 0.0678 - acc: 0.9764 - val_loss: 0.0694 - val_acc: 0.9757\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f8f5071d588>"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "intermediate_model_1.fit(x_train, y_train, epochs = 4, batch_size = 16, validation_data = (x_valid, y_valid))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "intermediate_model_1.save('intermediate_model_1.h5')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>Intermediate model 2: 2 extra layers, epochs = 16, batch_size = 32</h3><br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_28 (Conv2D)           (None, 32, 32, 64)        1792      \n",
      "_________________________________________________________________\n",
      "batch_normalization_28 (Batc (None, 32, 32, 64)        256       \n",
      "_________________________________________________________________\n",
      "activation_28 (Activation)   (None, 32, 32, 64)        0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_28 (MaxPooling (None, 16, 16, 64)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_29 (Conv2D)           (None, 16, 16, 64)        36928     \n",
      "_________________________________________________________________\n",
      "batch_normalization_29 (Batc (None, 16, 16, 64)        256       \n",
      "_________________________________________________________________\n",
      "activation_29 (Activation)   (None, 16, 16, 64)        0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_29 (MaxPooling (None, 8, 8, 64)          0         \n",
      "_________________________________________________________________\n",
      "conv2d_30 (Conv2D)           (None, 8, 8, 64)          36928     \n",
      "_________________________________________________________________\n",
      "batch_normalization_30 (Batc (None, 8, 8, 64)          256       \n",
      "_________________________________________________________________\n",
      "activation_30 (Activation)   (None, 8, 8, 64)          0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_30 (MaxPooling (None, 4, 4, 64)          0         \n",
      "_________________________________________________________________\n",
      "flatten_17 (Flatten)         (None, 1024)              0         \n",
      "_________________________________________________________________\n",
      "dropout_17 (Dropout)         (None, 1024)              0         \n",
      "_________________________________________________________________\n",
      "dense_33 (Dense)             (None, 64)                65600     \n",
      "_________________________________________________________________\n",
      "dense_34 (Dense)             (None, 1)                 65        \n",
      "=================================================================\n",
      "Total params: 142,081\n",
      "Trainable params: 141,697\n",
      "Non-trainable params: 384\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "intermediate_model_2 = build_model(num_layers = 3)\n",
    "intermediate_model_2.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "intermediate_model_2.compile(optimizer=RMSprop(lr=1e-4),\n",
    "              loss='binary_crossentropy',\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 11500 samples, validate on 6000 samples\n",
      "Epoch 1/16\n",
      "11500/11500 [==============================] - 24s 2ms/step - loss: 0.1666 - acc: 0.9343 - val_loss: 0.1071 - val_acc: 0.9570\n",
      "Epoch 2/16\n",
      "11500/11500 [==============================] - 23s 2ms/step - loss: 0.0847 - acc: 0.9681 - val_loss: 0.0787 - val_acc: 0.9707\n",
      "Epoch 3/16\n",
      "11500/11500 [==============================] - 23s 2ms/step - loss: 0.0708 - acc: 0.9709 - val_loss: 0.0481 - val_acc: 0.9827\n",
      "Epoch 4/16\n",
      "11500/11500 [==============================] - 22s 2ms/step - loss: 0.0594 - acc: 0.9783 - val_loss: 0.1365 - val_acc: 0.9520\n",
      "Epoch 5/16\n",
      "11500/11500 [==============================] - 22s 2ms/step - loss: 0.0471 - acc: 0.9826 - val_loss: 0.0611 - val_acc: 0.9795\n",
      "Epoch 6/16\n",
      "11500/11500 [==============================] - 22s 2ms/step - loss: 0.0392 - acc: 0.9854 - val_loss: 0.0413 - val_acc: 0.9848\n",
      "Epoch 7/16\n",
      "11500/11500 [==============================] - 22s 2ms/step - loss: 0.0377 - acc: 0.9857 - val_loss: 0.0283 - val_acc: 0.9900\n",
      "Epoch 8/16\n",
      "11500/11500 [==============================] - 22s 2ms/step - loss: 0.0294 - acc: 0.9887 - val_loss: 0.0420 - val_acc: 0.9862\n",
      "Epoch 9/16\n",
      "11500/11500 [==============================] - 23s 2ms/step - loss: 0.0214 - acc: 0.9922 - val_loss: 0.0273 - val_acc: 0.9905\n",
      "Epoch 10/16\n",
      "11500/11500 [==============================] - 22s 2ms/step - loss: 0.0229 - acc: 0.9908 - val_loss: 0.0283 - val_acc: 0.9905\n",
      "Epoch 11/16\n",
      "11500/11500 [==============================] - 22s 2ms/step - loss: 0.0218 - acc: 0.9927 - val_loss: 0.0240 - val_acc: 0.9915\n",
      "Epoch 12/16\n",
      "11500/11500 [==============================] - 23s 2ms/step - loss: 0.0171 - acc: 0.9942 - val_loss: 0.0247 - val_acc: 0.9920\n",
      "Epoch 13/16\n",
      "11500/11500 [==============================] - 22s 2ms/step - loss: 0.0155 - acc: 0.9950 - val_loss: 0.0288 - val_acc: 0.9912\n",
      "Epoch 14/16\n",
      "11500/11500 [==============================] - 23s 2ms/step - loss: 0.0148 - acc: 0.9949 - val_loss: 0.0288 - val_acc: 0.9910\n",
      "Epoch 15/16\n",
      "11500/11500 [==============================] - 23s 2ms/step - loss: 0.0127 - acc: 0.9950 - val_loss: 0.0331 - val_acc: 0.9895\n",
      "Epoch 16/16\n",
      "11500/11500 [==============================] - 23s 2ms/step - loss: 0.0129 - acc: 0.9961 - val_loss: 0.0681 - val_acc: 0.9783\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f7eb525ea20>"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "intermediate_model_2.fit(x_train, y_train, epochs = 16, batch_size = 32, validation_data = (x_valid, y_valid))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3> Accuracy target accomplished. Final training and predictions</h3>\n",
    "We have reached 99% accuracy, so we will save this as the final model, train it on the full dataset, and make predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/16\n",
      "17500/17500 [==============================] - 33s 2ms/step - loss: 0.1479 - acc: 0.9404\n",
      "Epoch 2/16\n",
      "17500/17500 [==============================] - 32s 2ms/step - loss: 0.0738 - acc: 0.9731\n",
      "Epoch 3/16\n",
      "17500/17500 [==============================] - 33s 2ms/step - loss: 0.0555 - acc: 0.9801\n",
      "Epoch 4/16\n",
      "17500/17500 [==============================] - 32s 2ms/step - loss: 0.0445 - acc: 0.9834\n",
      "Epoch 5/16\n",
      "17500/17500 [==============================] - 32s 2ms/step - loss: 0.0358 - acc: 0.9872\n",
      "Epoch 6/16\n",
      "17500/17500 [==============================] - 32s 2ms/step - loss: 0.0291 - acc: 0.9903\n",
      "Epoch 7/16\n",
      "17500/17500 [==============================] - 32s 2ms/step - loss: 0.0247 - acc: 0.9905\n",
      "Epoch 8/16\n",
      "17500/17500 [==============================] - 32s 2ms/step - loss: 0.0235 - acc: 0.9913\n",
      "Epoch 9/16\n",
      "17500/17500 [==============================] - 32s 2ms/step - loss: 0.0211 - acc: 0.9927\n",
      "Epoch 10/16\n",
      "17500/17500 [==============================] - 32s 2ms/step - loss: 0.0201 - acc: 0.9929\n",
      "Epoch 11/16\n",
      "17500/17500 [==============================] - 32s 2ms/step - loss: 0.0163 - acc: 0.9939\n",
      "Epoch 12/16\n",
      "17500/17500 [==============================] - 32s 2ms/step - loss: 0.0138 - acc: 0.9951\n",
      "Epoch 13/16\n",
      "17500/17500 [==============================] - 31s 2ms/step - loss: 0.0139 - acc: 0.9951\n",
      "Epoch 14/16\n",
      "17500/17500 [==============================] - 31s 2ms/step - loss: 0.0127 - acc: 0.9956\n",
      "Epoch 15/16\n",
      "17500/17500 [==============================] - 31s 2ms/step - loss: 0.0128 - acc: 0.9957\n",
      "Epoch 16/16\n",
      "17500/17500 [==============================] - 31s 2ms/step - loss: 0.0110 - acc: 0.9959\n"
     ]
    }
   ],
   "source": [
    "final_model = build_model(num_layers = 3)\n",
    "\n",
    "final_model.compile(optimizer=RMSprop(lr=1e-4),\n",
    "              loss='binary_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "final_model.fit(X_train, Y_train, epochs=16, batch_size=32)\n",
    "\n",
    "final_model.save('final_model.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create an output file with predictions\n",
    "pred = final_model.predict(X_test)\n",
    "\n",
    "\n",
    "df = pd.DataFrame({\n",
    "    'id': [f for f in testing_images],\n",
    "    'has_cactus': [int(x[0] > 0.5) for x in pred]\n",
    "})\n",
    "\n",
    "df.to_csv('predictions.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_31 (Conv2D)           (None, 32, 32, 64)        1792      \n",
      "_________________________________________________________________\n",
      "batch_normalization_31 (Batc (None, 32, 32, 64)        256       \n",
      "_________________________________________________________________\n",
      "activation_31 (Activation)   (None, 32, 32, 64)        0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_31 (MaxPooling (None, 16, 16, 64)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_32 (Conv2D)           (None, 16, 16, 64)        36928     \n",
      "_________________________________________________________________\n",
      "batch_normalization_32 (Batc (None, 16, 16, 64)        256       \n",
      "_________________________________________________________________\n",
      "activation_32 (Activation)   (None, 16, 16, 64)        0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_32 (MaxPooling (None, 8, 8, 64)          0         \n",
      "_________________________________________________________________\n",
      "conv2d_33 (Conv2D)           (None, 8, 8, 64)          36928     \n",
      "_________________________________________________________________\n",
      "batch_normalization_33 (Batc (None, 8, 8, 64)          256       \n",
      "_________________________________________________________________\n",
      "activation_33 (Activation)   (None, 8, 8, 64)          0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_33 (MaxPooling (None, 4, 4, 64)          0         \n",
      "_________________________________________________________________\n",
      "flatten_18 (Flatten)         (None, 1024)              0         \n",
      "_________________________________________________________________\n",
      "dropout_18 (Dropout)         (None, 1024)              0         \n",
      "_________________________________________________________________\n",
      "dense_35 (Dense)             (None, 64)                65600     \n",
      "_________________________________________________________________\n",
      "dense_36 (Dense)             (None, 1)                 65        \n",
      "=================================================================\n",
      "Total params: 142,081\n",
      "Trainable params: 141,697\n",
      "Non-trainable params: 384\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "final_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "capstone",
   "language": "python",
   "name": "capstone"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
